{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chemical-passion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to prepare a Pipeline model and dataset for EXPAI\n",
    "\n",
    "Welcome to this EXPAI tutorial. We share with you a sample code to implement a Pipeline using Python. We strongly recommend using this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "binary-deposit",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn import metrics as ms\n",
    "import pickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-motorcycle",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Loading the dataset**\n",
    "\n",
    "We use Pandas function for reading a CSV file. Consider other functions if your file is not CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dominant-blues",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Gas</td>\n",
       "      <td>yes</td>\n",
       "      <td>2010</td>\n",
       "      <td>Kuga</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>173</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Gas</td>\n",
       "      <td>yes</td>\n",
       "      <td>2011</td>\n",
       "      <td>E-Class</td>\n",
       "      <td>rear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>135</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2008</td>\n",
       "      <td>CL 550</td>\n",
       "      <td>rear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>van</td>\n",
       "      <td>162</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>yes</td>\n",
       "      <td>2012</td>\n",
       "      <td>B 180</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2013</td>\n",
       "      <td>X-Trail</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             car    price       body  mileage  engV engType registration  \\\n",
       "0           Ford  15500.0  crossover       68   2.5     Gas          yes   \n",
       "1  Mercedes-Benz  20500.0      sedan      173   1.8     Gas          yes   \n",
       "2  Mercedes-Benz  35000.0      other      135   5.5  Petrol          yes   \n",
       "3  Mercedes-Benz  17800.0        van      162   1.8  Diesel          yes   \n",
       "5         Nissan  16600.0  crossover       83   2.0  Petrol          yes   \n",
       "\n",
       "   year    model  drive  \n",
       "0  2010     Kuga   full  \n",
       "1  2011  E-Class   rear  \n",
       "2  2008   CL 550   rear  \n",
       "3  2012    B 180  front  \n",
       "5  2013  X-Trail   full  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the sample file\n",
    "original_sample_path = os.path.abspath(\"./car_ad_display.csv\")\n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv(original_sample_path, encoding='iso-8859-1', sep = \";\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-blend",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "### Simple data cleaning\n",
    "\n",
    "In this section, we clean some outliers and corrupted entries we found in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "earlier-terrain",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop registers with negative price (corrupted)\n",
    "df = df.drop(df[df.price <= 0 ].index)\n",
    "\n",
    "# Drop outliers\n",
    "df = df.drop(df[df.engV > 40].index)\n",
    "\n",
    "# Drop null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-reviewer",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "### Train-Test split\n",
    "\n",
    "Divide the dataset into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "talented-crowd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select target column\n",
    "y_train = df[\"price\"]\n",
    "\n",
    "# Drop target from input\n",
    "x_train = df.drop([\"price\"], axis=1)\n",
    "\n",
    "# Split with 20% for test\n",
    "data_train, data_test, label_train, label_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-difficulty",
   "metadata": {},
   "source": [
    "### Store input data\n",
    "\n",
    "It is really important to store the very same data we used for train-test split. This will be the input dataset for EXPAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./expai_input_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-aerospace",
   "metadata": {},
   "source": [
    "###Â Create a Pipeline\n",
    "\n",
    "Pipelines are implemented by Scikit-Learn and allow users to build an unique object for the whole analyticial process.\n",
    "\n",
    "In this case, we will build a Pipeline that:\n",
    "- Encodes categorical variables\n",
    "- Scales numerical variables\n",
    "- Implements a XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chicken-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformer for numerical and categorical variables\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [\"mileage\", \"engV\", \"year\"]),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='ignore'), [\"car\", \"body\", \"engType\", \"registration\", \"model\", \"drive\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "coordinate-component",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define XGBoost Regressor parameters\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# Init model\n",
    "model = xgb.XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "heavy-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['mileage', 'engV', 'year']),\n",
       "                                                 ('cat',\n",
       "                                                  OrdinalEncoder(handle_unknown='ignore'),\n",
       "                                                  ['car', 'body', 'engType',\n",
       "                                                   'registration', 'model',\n",
       "                                                   'drive'])])),\n",
       "                ('model',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=0.7, eta=0.05,\n",
       "                              eval_...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.0500000007, max_delta_step=0,\n",
       "                              max_depth=5, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              silent=1, subsample=0.7, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline object where steps are transformation and model.\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', transformer),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "clf.fit(X = data_train, y = label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-camcorder",
   "metadata": {},
   "source": [
    "### Measure performance\n",
    "\n",
    "Check the performance of the model we have just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "essential-louis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6125.9272, 13683.277 , 18706.371 , ..., 35528.973 , 55109.83  ,\n",
       "        2186.3943], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = clf.predict(data_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "regulation-precipitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51754384.06679244"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.mean_squared_error(label_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-tissue",
   "metadata": {},
   "source": [
    "### Export model using Pickle\n",
    "\n",
    "We use Pickle to export the Pipeline object that will be uploaded to EXPAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "golden-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(\"./model_pipeline.pkl\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
