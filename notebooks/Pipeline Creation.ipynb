{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floppy-credits",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cómo crear el modelo y su dataset para explicarlo usando EXPAI\n",
    "\n",
    "Bienvenido/a a este primer producto de EXPAI para explicar los modelos analíticos de tu proceso de negocio. Para facilitar la incorporación de nuestros servicios en vuestros procesos de negocio, hemos preparado una demo explicando cómo generar los datos que necesita EXPAI.\n",
    "\n",
    "Recuerda que en caso de encontraros con cualquier error o dificultad, podéis escribirnos a info@expai.io y la resolveremos lo antes posible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-lover",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Creando el dataset que usaremos para crear el modelo de estimación de precio de venta de vehículos\n",
    "\n",
    "En este caso de uso vamos a crear un modelo de estimación de precio de venta para vehículos de segunda mano. Para ello tenemos un dataset que nos ha pasado el equipo de producto cuyos campos son:\n",
    "\n",
    "- car: marca del vehículo.\n",
    "- price: precio de venta real.\n",
    "- body: tipo de carrocería del vehículo.\n",
    "- mileage: kilometraje, en millas, del vehículo.\n",
    "- engV: tamaño del motor.\n",
    "- engType: tipo de combustible.\n",
    "- registration: indica si el vehículo estaba registrado.\n",
    "- year: año del vehículo.\n",
    "- model: modelo del vehículo.\n",
    "- drive: tipo de tracción.\n",
    "\n",
    "En EXPAI se pueden subir tres tipos de datasets, cuyo uso dependerá de cómo hayamos creado el modelo:\n",
    "\n",
    "1. Si el modelo se ha creado usando Pipeline: en este caso la muestra que deberemos subir a EXPAI es la muestra original sin transformar, ya que el Pipeline que subiremos a EXPAI sabrá cómo transformarlo.\n",
    "\n",
    "2. Si el modelo no se ha creado usando Pipeline: en este caso la muestra que deberemos subir a EXPAI pueden ser dos:\n",
    "\n",
    "    - Muestra transformada usada para entrenar el modelo: deberemos subir a EXPAI el dato transformado que habremos usado para entrenar el modelo (conocido popularmente como X).\n",
    "    - Muestra sin original sin transformar (muestra display): si se puede asegurar la existencia de una relación 1:1 entre las muestras transformadas y la original mediante el índice de las mismas, se puede subir la muestra original sin transformar a EXPAI (marcada como display) de tal manera que el sistema use el valor sin transformar para generar las gráficas de las explicaciones. Esto se hace con el objetivo de plantear gráficas userfriendly y entendibles por los usuarios no técnicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "common-agenda",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn import metrics as ms\n",
    "import pickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-reservation",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Cargamos el dato**\n",
    "\n",
    "El dataset que nos han pasado es un fichero .csv, por lo que para leerlo usaremos el método _read_csv_ de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "burning-translator",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Gas</td>\n",
       "      <td>yes</td>\n",
       "      <td>2010</td>\n",
       "      <td>Kuga</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>173</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Gas</td>\n",
       "      <td>yes</td>\n",
       "      <td>2011</td>\n",
       "      <td>E-Class</td>\n",
       "      <td>rear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>135</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2008</td>\n",
       "      <td>CL 550</td>\n",
       "      <td>rear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>van</td>\n",
       "      <td>162</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>yes</td>\n",
       "      <td>2012</td>\n",
       "      <td>B 180</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2013</td>\n",
       "      <td>X-Trail</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             car    price       body  mileage  engV engType registration  \\\n",
       "0           Ford  15500.0  crossover       68   2.5     Gas          yes   \n",
       "1  Mercedes-Benz  20500.0      sedan      173   1.8     Gas          yes   \n",
       "2  Mercedes-Benz  35000.0      other      135   5.5  Petrol          yes   \n",
       "3  Mercedes-Benz  17800.0        van      162   1.8  Diesel          yes   \n",
       "5         Nissan  16600.0  crossover       83   2.0  Petrol          yes   \n",
       "\n",
       "   year    model  drive  \n",
       "0  2010     Kuga   full  \n",
       "1  2011  E-Class   rear  \n",
       "2  2008   CL 550   rear  \n",
       "3  2012    B 180  front  \n",
       "5  2013  X-Trail   full  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the sample file\n",
    "original_sample_path = os.path.abspath(\"/Users/danielhormigoruiz/Projects/jupyter/data/expai/demo_dag_dto/car_ad_display.csv\")\n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv(original_sample_path, encoding='iso-8859-1', sep = \";\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-attack",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Eliminamos aquellos con precio de venta negativo**\n",
    "\n",
    "Dado que el Pipeline de Scikit Learn no permite eliminar registros de un dataset, si tuviésemos que hacerlo tendremos que hacerlo antes de construir el Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "incredible-dining",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df.price <= 0 ].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-florida",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Eliminamos los engV a nulo y menores que 40**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "million-lodge",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(how = \"any\", subset = [\"engV\"])\n",
    "df = df.drop(df[df.engV > 40].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-orleans",
   "metadata": {},
   "source": [
    "**Eliminamos cualquier nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ideal-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-script",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Definimos los datasets de entrenamiento y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "solid-furniture",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df[\"price\"]\n",
    "x_train = df.drop([\"price\"], axis=1)\n",
    "data_train, data_test, label_train, label_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "exclusive-complaint",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.abspath(\"../../data/expai/demo_dag_dto/car_ad_display.csv\"), sep = \";\", encoding = \"iso-8859-1\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-coast",
   "metadata": {},
   "source": [
    "### Creando un modelo usando Pipelines\n",
    "\n",
    "Vamos a crear un modelo usando los Pipelines de Scikit Learn. Para ello, crearemos un Pipeline con los siguientes pasos:\n",
    "\n",
    "- Codificar las variables categóricas\n",
    "- Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "heated-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el Transformer de las variables categóricas\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [\"mileage\", \"engV\", \"year\"]),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='ignore'), [\"car\", \"body\", \"engType\", \"registration\", \"model\", \"drive\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "finished-easter",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos los parámetros de entrenamiento del XGBoost\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "model = xgb.XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "accomplished-feedback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:31:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['mileage', 'engV', 'year']),\n",
       "                                                 ('cat',\n",
       "                                                  OrdinalEncoder(handle_unknown='ignore'),\n",
       "                                                  ['car', 'body', 'engType',\n",
       "                                                   'registration', 'model',\n",
       "                                                   'drive'])])),\n",
       "                ('model',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=0.7, eta=0.05,\n",
       "                              eval_...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.0500000007, max_delta_step=0,\n",
       "                              max_depth=5, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              silent=1, subsample=0.7, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el pipeline de entrenamiento/ejecución del modelo\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', transformer),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "clf.fit(X = data_train, y = label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a54b1d78-83c2-4065-b806-fd389ced29ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MSE: 51754384.06679244\n",
      "\n",
      "    R2: 0.9171054473853012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    MSE: {ms.mean_squared_error(label_test, clf.predict(data_test))}\\n\n",
    "    R2: {ms.r2_score(label_test, clf.predict(data_test))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4b426-86ef-4271-9683-e80cbafa4ee5",
   "metadata": {},
   "source": [
    "**Exportamos el modelo mediante Pickle**\n",
    "\n",
    "Para poder subir el modelo a EXPAI es necesario exportar el pipeline usando Pickle, de manera genérica, o la función _save_ propia de la librería que estés usando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "executed-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo en local, y luego lo subimos a EXPAI\n",
    "model_path = os.path.abspath(\"../../data/expai/demo_dag_dto/model_pipeline.pkl\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0f819-6460-4004-b6d6-f3f6e01c58e8",
   "metadata": {},
   "source": [
    "### Creando un modelo sin Pipelines\n",
    "\n",
    "En la siguiente sección veremos como crear un modelo sin usar Pipelines de manera que podamos subirlo a EXPAI. En este caso deberás subir a EXPAI dos cosas:\n",
    "\n",
    "1. El dato transformado usado para entrenar/ejecutar el modelo.\n",
    "\n",
    "2. El modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad66e36-acd6-4688-8908-8f9c8f8c85f5",
   "metadata": {},
   "source": [
    "#### Creando el dataset\n",
    "\n",
    "El objetivo es crear el dataset que deberás subir a EXPAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda412ab-dc2d-43f0-9143-c91504aff3ce",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Codificamos las variables categóricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e6fbe6f-9b0d-4055-ab70-3c50a6621b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(df[c].values)) \n",
    "        df[c] = lbl.transform(list(df[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a12895f-0da6-4302-9d5b-3ebf36986ef7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car    price  body  mileage  engV  engType  registration  year  model  \\\n",
       "0   23  15500.0     0       68   2.5        1             1  2010    467   \n",
       "1   50  20500.0     3      173   1.8        1             1  2011    317   \n",
       "2   50  35000.0     2      135   5.5        3             1  2008    227   \n",
       "3   50  17800.0     5      162   1.8        0             1  2012    195   \n",
       "5   55  16600.0     0       83   2.0        3             1  2013    810   \n",
       "\n",
       "   drive  \n",
       "0      1  \n",
       "1      2  \n",
       "2      2  \n",
       "3      0  \n",
       "5      1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed921b6f-27ea-486b-b289-80b805b4f0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**Guardamos el dataset**\n",
    "\n",
    "Siempre debemos indicar que hay una columna de índices (index = True), que será la que, en caso de querer lincar con su equivalente _display_, usaremos como clave para unir ambos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718da0a-aa10-43fc-97ce-e1f2fef7a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.abspath(\"../../data/expai/demo_dag_dto/sample.csv\"), sep = \";\", encoding = \"utf-8\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68277d2b-9545-498d-a491-f9c50883de2d",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo\n",
    "\n",
    "Y por último entrenamos el modelo de manera aislada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9432d98b-ed5d-48c2-823f-dc6921ed4ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividimos entre entrenamiento y test\n",
    "y_train = df[\"price\"]\n",
    "x_train = df.drop([\"price\"], axis=1)\n",
    "data_train, data_test, label_train, label_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "placed-slope",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debido al tipo de modelo, es necesario convertirlo a un tipo de matriz especial\n",
    "data_train_matrix = xgb.DMatrix(data_train, label_train)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "cv_output = xgb.cv(xgb_params, data_train_matrix, num_boost_round=1000, early_stopping_rounds=20,\n",
    "                   verbose_eval=50, show_stdv=False)\n",
    "num_boost_rounds = len(cv_output)\n",
    "model = xgb.train(dict(xgb_params, silent=0), data_train_matrix, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "greatest-metadata",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MSE: 35488563.50026055\n",
      "\n",
      "    R2: 0.9431582725340557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos \n",
    "y_predict = model.predict(xgb.DMatrix(data_test))\n",
    "\n",
    "# Y calculamos el MSE y R2\n",
    "print(f\"\"\"\n",
    "    MSE: {ms.mean_squared_error(label_test, y_predict)}\\n\n",
    "    R2: {ms.r2_score(label_test, y_predict)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f47cdb-b580-4138-a85b-68bf9c7170c0",
   "metadata": {},
   "source": [
    "**Exportamos el modelo mediante Pickle**\n",
    "\n",
    "Para poder subir el modelo a EXPAI es necesario exportar el pipeline usando Pickle, de manera genérica, o la función _save_ propia de la librería que estés usando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "magnetic-community",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(\"../../data/expai/demo_dag_dto/model.pkl\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
